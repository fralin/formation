{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0819306f",
   "metadata": {},
   "source": [
    "# 16 - Backpropagation dans les réseaux neuronaux\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Nous avons déjà écrit dans les chapitres précédents de notre tutoriel sur les réseaux neuronaux en Python. Les réseaux de notre chapitre Running Neural Networks n'ont pas la capacité d'apprendre. Ils ne peuvent être exécutés qu'avec des valeurs de poids définies de manière aléatoire. Ils ne permettent donc pas de résoudre les problèmes de classification. En revanche, les réseaux du chapitre Réseaux neuronaux simples étaient capables d'apprendre, mais nous n'utilisions les réseaux linéaires que pour les classes linéairement séparables.\n",
    "\n",
    "Bien entendu, nous souhaitons écrire des ANN généraux, capables d'apprendre. Pour ce faire, nous devons comprendre la rétro-propagation. La rétropropagation est une méthode couramment utilisée pour former les réseaux de neurones artificiels, en particulier les réseaux de neurones profonds. La rétropropagation est nécessaire pour calculer le gradient, dont nous avons besoin pour adapter les poids des matrices de poids. Les poids des neurones (nœuds) de notre réseau sont ajustés en calculant le gradient de la fonction de perte. À cette fin, un algorithme d'optimisation par descente de gradient est utilisé. On l'appelle également la propagation à rebours des erreurs.\n",
    "\n",
    "Très souvent, les gens sont effrayés par les mathématiques utilisées dans cette méthode. Nous essayons de l'expliquer en termes simples.\n",
    "\n",
    "Dans de nombreux articles ou tutoriels, l'explication de la descente de gradient commence par une montagne. Imaginons que vous soyez placé sur une montagne, pas nécessairement au sommet, par un hélicoptère, de nuit ou dans un brouillard épais. Imaginons encore que cette montagne se trouve sur une île et que vous voulez atteindre le niveau de la mer. Vous devez descendre, mais vous ne voyez presque rien, peut-être seulement quelques mètres. Votre tâche consiste à trouver votre chemin vers le bas, mais vous ne pouvez pas voir le chemin. Vous pouvez utiliser la méthode de la descente en gradient. Cela signifie que vous examinez la pente à votre position actuelle. Vous avancez dans la direction où la pente est la plus forte. Vous ne faites que quelques pas, puis vous vous arrêtez à nouveau pour vous réorienter. Cela signifie que vous appliquez à nouveau la procédure décrite précédemment, c'est-à-dire que vous recherchez la descente la plus raide.\n",
    "\n",
    "<center>\n",
    "    <img src=\"img/illustration16_1.png\" width=\"80%\">\n",
    "</center>\n",
    "\n",
    "En continuant ainsi, vous arriverez à une position où il n'y aura plus de descente.\n",
    "\n",
    "Chaque direction va vers le haut. Vous avez peut-être atteint le niveau le plus profond - le minimum global -, mais vous pourriez tout aussi bien être coincé dans un bassin. Si vous partez de la position située à droite de notre image, tout se passe bien, mais depuis la gauche, vous serez coincé dans un minimum local.\n",
    "\n",
    "## La rétropropagation en détail\n",
    "\n",
    "Nous devons maintenant entrer dans les détails, c'est-à-dire dans les mathématiques.\n",
    "\n",
    "Nous allons commencer par le cas le plus simple. Nous examinons un réseau linéaire. Les réseaux neuronaux linéaires sont des réseaux où le signal de sortie est créé en additionnant tous les signaux d'entrée pondérés. Aucune fonction d'activation ne sera appliquée à cette somme, ce qui explique la linéarité.\n",
    "\n",
    "Nous utiliserons le réseau simple suivant:\n",
    "\n",
    "<center>\n",
    "    <img src=\"img/illustration16_2.png\" width=\"50%\">\n",
    "</center>\n",
    "\n",
    "Lorsque nous formons le réseau, nous avons des échantillons et les étiquettes correspondantes. Pour chaque valeur de sortie $o_i$ nous avons une étiquette $t_i$ qui est la cible ou la valeur souhaitée. Si l'étiquette est égale à la sortie, le résultat est correct et le réseau neuronal n'a pas commis d'erreur. En principe, l'erreur est la différence entre la cible et la sortie réelle :\n",
    "\n",
    "$$e_i = t_i - o_i$$\n",
    "\n",
    "Nous utiliserons plus tard une fonction d'erreur quadratique, car elle présente de meilleures caractéristiques pour l'algorithme :\n",
    "\n",
    "<center>\n",
    "    <img src=\"img/illustration16_3.png\" width=\"60%\">\n",
    "</center>\n",
    "\n",
    "Nous allons examiner la valeur de sortie $o_1$ qui dépend des valeurs $w_{11}$,$w_{12}$, $w_{13}$ et $w_{14}$. Supposons que la valeur calculée $(o_1)$ est de 0,92 et que la valeur souhaitée $(t_1)$ est 1. Dans ce cas, l'erreur est de :\n",
    "\n",
    "$$e_1 = t_1 - o_1 = 1 - 0.92 = 0.08$$\n",
    "\n",
    "<center>\n",
    "    <img src=\"img/illustration16_4.png\" width=\"50%\">\n",
    "</center>\n",
    "\n",
    "En fonction de cette erreur, nous devons modifier les poids des valeurs entrantes en conséquence. Nous avons quatre poids, donc nous pourrions répartir l'erreur de manière égale. Pourtant, il est plus logique de le faire proportionnellement, en fonction des valeurs de poids. Plus un poids est grand par rapport aux autres poids, plus il est responsable de l'erreur. Cela signifie que nous pouvons calculer la fraction de l'erreur $e_1$ dans $w_{11}$ comme :\n",
    "\n",
    "$$e_1 \\cdot \\frac{w_{11}}{\\sum_{i=1}^{4} w_{1i}}$$\n",
    "\n",
    "Cela signifie que dans notre exemple :\n",
    "\n",
    "$$0.08 \\cdot \\frac{0.6}{0.6 + 0.1 + 0.15 + 0.25} = 0.0343$$\n",
    "\n",
    "L'erreur totale dans notre matrice de poids entre la couche cachée et la couche de sortie - nous l'avons appelée dans notre chapitre précédent \" who\" - ressemble à ceci:\n",
    "\n",
    "$$e_{who} = \n",
    "\\begin{bmatrix}\n",
    "    \\frac{w_{11}}{\\sum_{i=1}^{4} w_{1i}} & \\frac{w_{21}}{\\sum_{i=1}^{4} w_{2i}}  & \\frac{w_{31}}{\\sum_{i=1}^{4} w_{3i}} \\\\\n",
    "    \\frac{w_{12}}{\\sum_{i=1}^{4} w_{1i}} & \\frac{w_{22}}{\\sum_{i=1}^{4} w_{2i}}  & \\frac{w_{32}}{\\sum_{i=1}^{4} w_{3i}}\\\\\n",
    "    \\frac{w_{13}}{\\sum_{i=1}^{4} w_{1i}} & \\frac{w_{23}}{\\sum_{i=1}^{4} w_{2i}}  & \\frac{w_{33}}{\\sum_{i=1}^{4} w_{3i}}\\\\\n",
    "        \\frac{w_{14}}{\\sum_{i=1}^{4} w_{1i}} & \\frac{w_{24}}{\\sum_{i=1}^{4} w_{2i}}   & \\frac{w_{34}}{\\sum_{i=1}^{4} w_{3i}}\\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "    e_1 \\\\\n",
    "    e_2 \\\\\n",
    "    e_3\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b6bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example who:\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "who = np.array([[0.6, 0.5, 0.06],\n",
    "                [0.3, 0.2, 0.8],\n",
    "                [0.2, 0.1, 0.7],\n",
    "                [0.12, 0.7, 0.54]])\n",
    "\n",
    "e = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "who * e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc931a1",
   "metadata": {},
   "source": [
    "Vous pouvez voir que le dénominateur dans la matrice de gauche est toujours le même pour chaque colonne. Il fonctionne comme un facteur d'échelle. Nous pouvons le laisser tomber pour que le calcul soit beaucoup plus simple :\n",
    "\n",
    "$$e_{who} = \n",
    "\\begin{bmatrix}\n",
    "    w_{11} & w_{21} & w_{31} \\\\\n",
    "    w_{12} & w_{22} & w_{32}\\\\\n",
    "    w_{13} & w_{23} & w_{33} \\\\\n",
    "    w_{14} & w_{24} & w_{34} \\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "    e_1 \\\\\n",
    "    e_2 \\\\\n",
    "    e_3\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Si vous comparez la matrice de droite avec la matrice 'who' de notre chapitre Reseau de neurones avec python et nupy, vous remarquerez qu'elle est la transposée de 'who'.\n",
    "\n",
    "$$e_{who} = who.T \\cdot e$$\n",
    "\n",
    "C'était donc la partie facile pour les réseaux neuronaux linéaires. Jusqu'à présent, nous n'avons pas pris en compte la fonction d'activation.\n",
    "\n",
    "Nous voulons calculer l'erreur dans un réseau avec une fonction d'activation, c'est-à-dire un réseau non linéaire. La dérivation de la fonction d'erreur décrit la pente. Comme nous l'avons mentionné au début de ce chapitre, nous voulons descendre. La dérivation décrit comment l'erreur $E$ change lorsque le poids$ w_{kj}$ change :\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial w_{kj}}$$\n",
    "\n",
    "La fonction d'erreur E sur tous les noeuds de sortie $o_1(i = 1, \\cdots n)$ où n est le nombre total de nœuds de sortie :\n",
    "\n",
    "$$E = \\sum_{i=1}^{n} \\frac{1}{2} (t_i - o_i)^2$$\n",
    "\n",
    "Maintenant, nous pouvons insérer ceci dans notre dérivation :\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial w_{kj}} = \\frac{\\partial}{\\partial w_{kj}} \\frac{1}{2} \\sum_{i=1}^{n} (t_i - o_i)^2$$\n",
    "\n",
    "Si vous jetez un coup d'œil à notre exemple de réseau, vous verrez qu'un nœud de sortie $o_k$ ne dépend que des signaux d'entrée créés avec les poids $w_{ki}$ avec $i=1,\\cdots , m$ et $m$ le nombre de nœuds cachés.\n",
    "\n",
    "Le schéma suivant permet de mieux comprendre ce phénomène :\n",
    "\n",
    "<center>\n",
    "    <img src=\"img/illustration16_5.png\" width=\"50%\">\n",
    "</center>\n",
    "\n",
    "\n",
    "Cela signifie que nous pouvons calculer l'erreur pour chaque nœud de sortie indépendamment les uns des autres. Cela signifie que nous pouvons supprimer toutes les expressions $t_i-o_i$ avec $i \\neq k$ de notre sommation. Ainsi, le calcul de l'erreur pour un nœud k semble beaucoup plus simple maintenant :\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial w_{kj}} = \\frac{\\partial}{\\partial w_{kj}} \\frac{1}{2} (t_k - o_k)^2$$\n",
    "\n",
    "La valeur cible $t_k$ est une constante, car elle ne dépend d'aucun signal d'entrée ni d'aucun poids. Nous pouvons appliquer la règle de la chaîne pour la différenciation du terme précédent afin de simplifier les choses :\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial w_{kj}} = \\frac{\\partial E}{\\partial o_{k}} \\cdot \\frac{\\partial o_k}{\\partial w_{kj}}$$\n",
    "\n",
    "Dans le chapitre précédent de notre tutoriel, nous avons utilisé la fonction sigmoïde comme fonction d'activation :\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "Le nœud de sortie $o_k$ est calculé en appliquant la fonction sigmoïde à la somme des signaux d'entrée pondérés. Cela signifie que nous pouvons transformer davantage notre terme dérivé en remplaçant $o_k$ par cette fonction :\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial w_{kj}} = (t_k - o_k) \\cdot \\frac{\\partial }{\\partial w_{kj}} \\sigma(\\sum_{i=1}^{m} w_{ki}h_i)$$\n",
    "\n",
    "où $m$ est le nombre de nœuds cachés.\n",
    "\n",
    "La fonction sigmoïde est facile à différencier :\n",
    "$$\\frac{\\partial \\sigma(x)}{\\partial x} = \\sigma(x) \\cdot (1 - \\sigma(x))$$\n",
    "\n",
    "La différenciation complète ressemble à ceci maintenant :\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial w_{kj}} = (t_k - o_k) \\cdot  \\sigma(\\sum_{i=1}^{m} w_{ki}h_i) \\cdot (1 -  \\sigma(\\sum_{i=1}^{m} w_{ki} h_i)) \\frac{\\partial }{\\partial w_{kj}} \\sum_{i=1}^{m} w_{ki}h_i$$\n",
    "\n",
    "La dernière partie doit être différenciée par rapport à $w_{kj}$. Cela signifie que la dérivation de tous les produits sera égale à 0, sauf le terme $w_{kj}h_j$ dont la dérivée est $h_j$ par rapport à $w_{kj}$ :\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial w_{kj}} = (t_k - o_k) \\cdot  \\sigma(\\sum_{i=1}^{m} w_{ki}h_i) \\cdot (1 -  \\sigma(\\sum_{i=1}^{m} w_{ki}h_i)) \\cdot h_j$$\n",
    "\n",
    "C'est ce dont nous avons besoin pour implémenter la méthode \" train \" de notre classe NeuralNetwork dans le chapitre suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580167a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "py10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
