{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fbee31c-68e0-4b43-83a3-3d120d5452f6",
   "metadata": {},
   "source": [
    "# 6. Data sets artificielles avec Scikit-Learn\n",
    "\n",
    "\n",
    "## Générer des données synthétiques avec Python\n",
    "\n",
    "L'un des problèmes de l'apprentissage automatique, en particulier lorsque vous débutez et que vous souhaitez vous familiariser avec les algorithmes, est qu'il est souvent difficile d'obtenir des données de test adaptées. Certaines coûtent très cher, d'autres ne sont pas disponibles librement car elles sont protégées par des droits d'auteur. Par conséquent, les données de test générées artificiellement peuvent être une solution dans certains cas.\n",
    "\n",
    "Ce chapitre traite de la création de données artificielles. Dans les chapitres précédents, nous avons appris que Scikit-Learn (sklearn) contient différents ensembles de données. D'une part, il y a de petits ensembles de données __jouets__, mais il offre également des ensembles de données plus importants qui sont souvent utilisés dans la communauté de l'apprentissage automatique pour tester les algorithmes ou également servir de référence. Il nous fournit des données provenant du \"monde réel\".\n",
    "\n",
    "Tout cela est formidable, mais dans de nombreux cas, ce n'est pas encore suffisant. Vous avez peut-être trouvé le bon type de données, mais vous avez besoin de plus de données de ce type ou les données ne sont pas tout à fait le type de données que vous recherchiez, par exemple, vous avez peut-être besoin de données plus complexes ou moins complexes. C'est à ce moment que vous devez envisager de créer les données vous-même. C'est là que ```sklearn``` peut vous aider. Il comprend divers générateurs d'échantillons aléatoires qui peuvent être utilisés pour créer des ensembles de données artificielles sur mesure. Des ensembles de données qui répondent à vos idées de taille et de complexité.\n",
    "\n",
    "Le code Python suivant est un exemple simple dans lequel nous créons des données météorologiques artificielles pour certaines villes allemandes. Nous utilisons Pandas et Numpy pour créer les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f949f1e-6d42-48e6-babe-ceeee01f8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "cities = ['Berlin', 'Frankfurt', 'Hamburg', \n",
    "          'Nuremberg', 'Munich', 'Stuttgart',\n",
    "          'Hanover', 'Saarbruecken', 'Cologne',\n",
    "          'Constance', 'Freiburg', 'Karlsruhe'\n",
    "         ]\n",
    "\n",
    "n= len(cities)\n",
    "data = {'Temperature': np.random.normal(24, 3, n),\n",
    "        'Humidity': np.random.normal(78, 2.5, n),\n",
    "        'Wind': np.random.normal(15, 4, n)\n",
    "       }\n",
    "df = pd.DataFrame(data=data, index=cities)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dc4c5f-8076-496f-8034-eb33346c095a",
   "metadata": {},
   "source": [
    "### Un autre exemple\n",
    "\n",
    "Nous allons créer des données artificielles pour quatre types de fleurs inexistants. Si les noms vous rappellent des langages de programmation et des pizzas, ce ne sera pas une coïncidence :\n",
    "\n",
    "- Flos Pythonem\n",
    "- Flos Java\n",
    "- Flos Margarita\n",
    "- Flos artificialis\n",
    "\n",
    "Les valeurs moyennes des couleurs RGB sont les suivantes :\n",
    "\n",
    "- (255, 0, 0)\n",
    "- (245, 107, 0)\n",
    "- (206, 99, 1)\n",
    "- (255, 254, 101)\n",
    "\n",
    "Le diamètre moyen du calice est :\n",
    "\n",
    "- 3.8\n",
    "- 3.3\n",
    "- 4.1\n",
    "- 2.9\n",
    "\n",
    "| Flos pythonem<br>(254, 0, 0)| Flos Java<br>(245, 107, 0)|\n",
    "| :---: | :---: |\n",
    "| Flos margarita <br>(206, 99, 1) | Flos artificialis <br> (255, 254, 101) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351003a2-06bd-4a79-8ca8-e5038d16c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm(\n",
    "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "\n",
    "def truncated_normal_floats(mean=0, sd=1, low=0, upp=10, num=100):\n",
    "    res = truncated_normal(mean=mean, sd=sd, low=low, upp=upp)\n",
    "    return res.rvs(num)\n",
    "\n",
    "def truncated_normal_ints(mean=0, sd=1, low=0, upp=10, num=100):\n",
    "    res = truncated_normal(mean=mean, sd=sd, low=low, upp=upp)\n",
    "    return res.rvs(num).astype(np.uint8)\n",
    "\n",
    "# number of items for each flower class:\n",
    "number_of_items_per_class = [190, 205, 230, 170]\n",
    "flowers = {}\n",
    "# flos Pythonem:\n",
    "number_of_items = number_of_items_per_class[0]\n",
    "reds = truncated_normal_ints(mean=254, sd=18, low=235, upp=256,\n",
    "                             num=number_of_items)\n",
    "greens = truncated_normal_ints(mean=107, sd=11, low=88, upp=127,\n",
    "                             num=number_of_items)\n",
    "blues = truncated_normal_ints(mean=0, sd=15, low=0, upp=20,\n",
    "                             num=number_of_items)\n",
    "calyx_dia = truncated_normal_floats(3.8, 0.3, 3.4, 4.2,\n",
    "                             num=number_of_items)\n",
    "data = np.column_stack((reds, greens, blues, calyx_dia))\n",
    "flowers[\"flos_pythonem\"] = data\n",
    "\n",
    "# flos Java:\n",
    "number_of_items = number_of_items_per_class[1]\n",
    "reds = truncated_normal_ints(mean=245, sd=17, low=226, upp=256,\n",
    "                             num=number_of_items)\n",
    "greens = truncated_normal_ints(mean=107, sd=11, low=88, upp=127,\n",
    "                             num=number_of_items)\n",
    "blues = truncated_normal_ints(mean=0, sd=10, low=0, upp=20,\n",
    "                             num=number_of_items)\n",
    "calyx_dia = truncated_normal_floats(3.3, 0.3, 3.0, 3.5,\n",
    "                             num=number_of_items)\n",
    "data = np.column_stack((reds, greens, blues, calyx_dia))\n",
    "flowers[\"flos_java\"] = data\n",
    "\n",
    "# flos Java:\n",
    "number_of_items = number_of_items_per_class[2]\n",
    "reds = truncated_normal_ints(mean=206, sd=17, low=175, upp=238,\n",
    "                             num=number_of_items)\n",
    "greens = truncated_normal_ints(mean=99, sd=14, low=80, upp=120,\n",
    "                             num=number_of_items)\n",
    "blues = truncated_normal_ints(mean=1, sd=5, low=0, upp=12,\n",
    "                             num=number_of_items)\n",
    "calyx_dia = truncated_normal_floats(4.1, 0.3, 3.8, 4.4,\n",
    "                             num=number_of_items)\n",
    "data = np.column_stack((reds, greens, blues, calyx_dia))\n",
    "flowers[\"flos_margarita\"] = data\n",
    "\n",
    "# flos artificialis:\n",
    "number_of_items = number_of_items_per_class[3]\n",
    "reds = truncated_normal_ints(mean=255, sd=8, low=2245, upp=2255,\n",
    "                             num=number_of_items)\n",
    "greens = truncated_normal_ints(mean=254, sd=10, low=240, upp=255,\n",
    "                             num=number_of_items)\n",
    "blues = truncated_normal_ints(mean=101, sd=5, low=90, upp=112,\n",
    "                             num=number_of_items)\n",
    "calyx_dia = truncated_normal_floats(2.9, 0.4, 2.4, 3.5,\n",
    "                             num=number_of_items)\n",
    "data = np.column_stack((reds, greens, blues, calyx_dia))\n",
    "flowers[\"flos_artificialis\"] = data\n",
    "\n",
    "\n",
    "data = np.concatenate((flowers[\"flos_pythonem\"], \n",
    "                      flowers[\"flos_java\"],\n",
    "                      flowers[\"flos_margarita\"],\n",
    "                      flowers[\"flos_artificialis\"]\n",
    "                     ), axis=0)\n",
    "\n",
    "# assigning the labels\n",
    "target = np.zeros(sum(number_of_items_per_class)) # 4 flowers\n",
    "previous_end = 0\n",
    "for i in range(1, 5):\n",
    "    num = number_of_items_per_class[i-1]\n",
    "    beg = previous_end\n",
    "    target[beg: beg + num] += i\n",
    "    previous_end = beg + num\n",
    "    \n",
    "conc_data = np.concatenate((data, target.reshape(target.shape[0], 1)),\n",
    "                           axis=1)\n",
    "\n",
    "np.savetxt(\"data/strange_flowers.txt\", conc_data, fmt=\"%2.2f\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00e6431-09ea-400e-9678-0929c814cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_names = list(flowers.keys())\n",
    "feature_names = ['red', 'green', 'blue', 'calyx']\n",
    "n = 4\n",
    "fig, ax = plt.subplots(n, n, figsize=(16, 16))\n",
    "\n",
    "colors = ['blue', 'red', 'green', 'yellow']\n",
    "\n",
    "for x in range(n):\n",
    "    for y in range(n):\n",
    "        xname = feature_names[x]\n",
    "        yname = feature_names[y]\n",
    "        for color_ind in range(1, len(target_names)+1):\n",
    "            ax[x, y].scatter(data[target==color_ind, x], \n",
    "                             data[target==color_ind, y],\n",
    "                             label=target_names[color_ind-1],\n",
    "                             c=colors[color_ind-1])\n",
    "\n",
    "        ax[x, y].set_xlabel(xname)\n",
    "        ax[x, y].set_ylabel(yname)\n",
    "        ax[x, y].legend(loc='upper left')\n",
    "\n",
    "\n",
    "plt.show() # scatter of strange flowers data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6eb47-0d25-4a5f-9712-7738418278e5",
   "metadata": {},
   "source": [
    "## Générer des données synthétiques avec Scikit-Learn\n",
    "\n",
    "Il est beaucoup plus facile d'utiliser les possibilités de Scikit-Learn pour créer des données synthétiques.\n",
    "\n",
    "Les fonctionnalités disponibles dans Scikit-Learn peuvent être regroupées comme suit\n",
    "\n",
    "1. Générateurs pour la classification et le clustering\n",
    "2. Générateurs pour la création de données pour la régression\n",
    "3. Générateurs pour l'apprentissage manifold\n",
    "4. Générateurs pour la décomposition\n",
    "\n",
    "### Générateurs pour la classification et le clustering\n",
    "Nous commençons avec la fonction ```make_blobs``` de sklearn.datasets pour créer des distributions de données semblables à des blobs. En fixant la valeur de ```centers``` à ```n_classes```, nous déterminons le nombre de blobs, c'est-à-dire les clusters. ```n_samples``` correspond au nombre total de points répartis équitablement entre les clusters. Si ```random_state``` n'est pas défini, nous aurons des résultats aléatoires à chaque fois que nous appelons la fonction. Nous passons un ```int``` à ce paramètre pour que les résultats soient reproductibles à travers plusieurs appels de la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec055b-03e9-4b1c-b31d-184e2b4fae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "n_classes = 4\n",
    "data, labels = make_blobs(n_samples=1000, \n",
    "                          centers=n_classes, \n",
    "                          random_state=100)\n",
    "\n",
    "labels[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08c2a5-6ecd-491b-ac61-b8aea9048402",
   "metadata": {},
   "source": [
    "Nous allons visualiser les custers blob précédemment créés avec matplotlib :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33697b3-b67e-4f5e-8ddb-5a6bc108209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some blobs\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colours = ('green', 'orange', 'blue', \"pink\")\n",
    "for label in range(n_classes):\n",
    "    ax.scatter(x=data[labels==label, 0], \n",
    "               y=data[labels==label, 1], \n",
    "               c=colours[label], \n",
    "               s=40, \n",
    "               label=label)\n",
    "\n",
    "ax.set(xlabel='X',\n",
    "       ylabel='Y',\n",
    "       title='Blobs Examples')\n",
    "\n",
    "\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237f0746-ba08-41f9-98db-5103351d831b",
   "metadata": {},
   "source": [
    "Les centres des gouttes ont été choisis aléatoirement dans l'exemple précédent. Dans l'exemple suivant, nous définissons les centres des blobs de manière explicite. Nous créons une liste avec les points centraux et la passons au paramètre centers :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8bdc16-5f39-439e-96bb-9ec1fdfabdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "centers = [[2, 3], [4, 5], [7, 9]]\n",
    "data, labels = make_blobs(n_samples=1000, \n",
    "                          centers=np.array(centers),\n",
    "                          random_state=1)\n",
    "\n",
    "labels[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f58a8e-a3fb-4949-99ae-0942bbd3b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some more blobs\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colours = ('green', 'orange', 'blue')\n",
    "for label in range(len(centers)):\n",
    "    ax.scatter(x=data[labels==label, 0], \n",
    "               y=data[labels==label, 1], \n",
    "               c=colours[label], \n",
    "               s=40, \n",
    "               label=label)\n",
    "\n",
    "ax.set(xlabel='X',\n",
    "       ylabel='Y',\n",
    "       title='Blobs Examples')\n",
    "\n",
    "\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d67c19-6038-4991-9f90-1452bfa9a935",
   "metadata": {},
   "source": [
    "Habituellement, vous souhaitez enregistrer vos ensembles de données créés artificiellement dans un fichier. Dans ce but, nous pouvons utiliser la fonction ```savetxt``` de numpy. Avant de faire cela, nous devons réorganiser nos données. Chaque ligne doit contenir à la fois les données et l'étiquette :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d9586-5e54-4747-9e09-364cfa6881f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = labels.reshape((labels.shape[0],1))\n",
    "all_data = np.concatenate((data, labels), axis=1)\n",
    "all_data[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48faf26-d6fc-4d08-8b1f-07fdea2f0049",
   "metadata": {},
   "source": [
    "Pour certaines personnes, il peut être compliqué de comprendre la combinaison de ```reshape``` et ```concatenate```. Par conséquent, vous pouvez voir un exemple extrêmement simple dans le code suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea80c0-7649-4ec2-a545-a6fe4f0f1a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array( [[1, 2], [3, 4]])\n",
    "b = np.array( [5, 6])\n",
    "b = b.reshape((b.shape[0], 1))\n",
    "print(b)\n",
    "\n",
    "x = np.concatenate( (a, b), axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b58e8-164b-4bc3-94f9-4b4194f1c14a",
   "metadata": {},
   "source": [
    "Nous utilisons la fonction numpy ```savetxt``` pour sauvegarder les données. Ne vous inquiétez pas du nom étrange, c'est juste pour le plaisir et pour des raisons qui seront bientôt claires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e36914-9d5a-4395-8c7a-737d2e0c147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"data/squirrels.txt\", \n",
    "           all_data,\n",
    "           fmt=['%.3f', '%.3f', '%1d'])\n",
    "all_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ca4cb-8368-4cd2-94a4-5694c0c41d72",
   "metadata": {},
   "source": [
    "### Lecture des données et reconversion en \"données\" et \"étiquettes\".\n",
    "\n",
    "Nous allons maintenant montrer comment lire à nouveau les données et comment les diviser à nouveau en données et en étiquettes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ed486-84af-415d-a3c0-cd55ec170cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = np.loadtxt(\"data/squirrels.txt\")\n",
    "\n",
    "data = file_data[:,:-1]\n",
    "labels = file_data[:,2:]\n",
    "\n",
    "labels = labels.reshape((labels.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970ef13-629e-434a-8de0-6d2d7a89b7f8",
   "metadata": {},
   "source": [
    "Nous avions appelé le fichier de données ```squirrels.txt```, car nous imaginions un étrange type d'animal vivant dans le désert du Sahara. Les valeurs ```x``` représentent les capacités de vision nocturne des animaux et les valeurs ```y``` correspondent à la couleur de la fourrure, allant du sable au noir. Nous avons trois sortes d'écureuils, 0, 1 et 2 (attention, nos écureuils sont des écureuils imaginaires et n'ont rien à voir avec les vrais écureuils du Sahara)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6685bd4-2528-4dcc-92c5-bd442009010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sahara squirrel dataset graph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colours = ('green', 'red', 'blue', 'magenta', 'yellow', 'cyan')\n",
    "n_classes = 3\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for n_class in range(0, n_classes):\n",
    "    ax.scatter(data[labels==n_class, 0], data[labels==n_class, 1], \n",
    "               c=colours[n_class], s=10, label=str(n_class))\n",
    "\n",
    "ax.set(xlabel='Night Vision',\n",
    "       ylabel='Fur color from sandish to black, 0 to 10 ',\n",
    "       title='Sahara Virtual Squirrel')\n",
    "\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22479076-e334-470b-adb9-4bc431e352eb",
   "metadata": {},
   "source": [
    "Nous allons mettre en forme nos données articifielles dans le code suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93396e-a9ab-4b0d-a134-eeac9f9efb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_sets = train_test_split(data, \n",
    "                       labels, \n",
    "                       train_size=0.8,\n",
    "                       test_size=0.2,\n",
    "                       random_state=42 # garantees same output for every run\n",
    "                      )\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = data_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b4677-7103-4d16-a508-f467cca6f8bf",
   "metadata": {},
   "source": [
    "Pour pouvoir les utiliser pour entrainer un modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c005fb3-0b03-4e0d-b3c3-1cdf8c2f1182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# create classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "# train\n",
    "knn.fit(train_data, train_labels)\n",
    "\n",
    "# test on test data:\n",
    "calculated_labels = knn.predict(test_data)\n",
    "calculated_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe2bb82-5d3f-451e-9e20-26f42f06ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(test_labels, calculated_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4744bf8d-cd33-41b4-a61d-1453fe4c6133",
   "metadata": {},
   "source": [
    "### Autres distributions intéressantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829fde0-8071-4b48-9142-2e3044fd432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import sklearn.datasets as ds\n",
    "data, labels = ds.make_moons(n_samples=150, \n",
    "                             shuffle=True, \n",
    "                             noise=0.19, \n",
    "                             random_state=None)\n",
    "\n",
    "data += np.array(-np.ndarray.min(data[:,0]), \n",
    "                 -np.ndarray.min(data[:,1]))\n",
    "\n",
    "np.ndarray.min(data[:,0]), np.ndarray.min(data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c853b38-beab-4a8e-87eb-b0c3054a5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moon graphs\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(data[labels==0, 0], data[labels==0, 1], \n",
    "               c='orange', s=40, label='oranges')\n",
    "ax.scatter(data[labels==1, 0], data[labels==1, 1], \n",
    "               c='blue', s=40, label='blues')\n",
    "\n",
    "ax.set(xlabel='X',\n",
    "       ylabel='Y',\n",
    "       title='Moons')\n",
    "\n",
    "\n",
    "#ax.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b5fb80-05d5-4f7d-a949-f7747f549732",
   "metadata": {},
   "source": [
    "Nous voulons mettre à l'échelle des valeurs qui sont dans une plage [min, max] dans une plage [a, b].\n",
    "\n",
    "$$f(x) = \\frac{(b-a)\\cdot(x - min)}{max - min} + a$$\n",
    "\n",
    "Nous utilisons maintenant cette formule pour transformer les coordonnées X et Y des données dans d'autres plages :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672d608-393f-456d-973f-85e45c4f20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_x_new, max_x_new = 33, 88\n",
    "min_y_new, max_y_new = 12, 20\n",
    "\n",
    "data, labels = ds.make_moons(n_samples=100, \n",
    "                             shuffle=True, \n",
    "                             noise=0.05, \n",
    "                             random_state=None)\n",
    "\n",
    "min_x, min_y = np.ndarray.min(data[:,0]), np.ndarray.min(data[:,1])\n",
    "max_x, max_y = np.ndarray.max(data[:,0]), np.ndarray.max(data[:,1])\n",
    "\n",
    "#data -= np.array([min_x, 0]) \n",
    "#data *= np.array([(max_x_new - min_x_new) / (max_x - min_x), 1])\n",
    "#data += np.array([min_x_new, 0]) \n",
    "\n",
    "#data -= np.array([0, min_y]) \n",
    "#data *= np.array([1, (max_y_new - min_y_new) / (max_y - min_y)])\n",
    "#data += np.array([0, min_y_new]) \n",
    "\n",
    "\n",
    "\n",
    "data -= np.array([min_x, min_y]) \n",
    "data *= np.array([(max_x_new - min_x_new) / (max_x - min_x), (max_y_new - min_y_new) / (max_y - min_y)])\n",
    "data += np.array([min_x_new, min_y_new]) \n",
    "\n",
    "\n",
    "#np.ndarray.min(data[:,0]), np.ndarray.max(data[:,0])\n",
    "data[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c900ec96-1dba-4a75-aa01-823e30057333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data, new_limits, inplace=False ):\n",
    "    if not inplace:\n",
    "        data = data.copy()\n",
    "    min_x, min_y = np.ndarray.min(data[:,0]), np.ndarray.min(data[:,1])\n",
    "    max_x, max_y = np.ndarray.max(data[:,0]), np.ndarray.max(data[:,1])\n",
    "    min_x_new, max_x_new = new_limits[0]\n",
    "    min_y_new, max_y_new = new_limits[1]\n",
    "    data -= np.array([min_x, min_y]) \n",
    "    data *= np.array([(max_x_new - min_x_new) / (max_x - min_x), (max_y_new - min_y_new) / (max_y - min_y)])\n",
    "    data += np.array([min_x_new, min_y_new]) \n",
    "    if inplace:\n",
    "        return None\n",
    "    else:\n",
    "        return data\n",
    "    \n",
    "    \n",
    "data, labels = ds.make_moons(n_samples=100, \n",
    "                             shuffle=True, \n",
    "                             noise=0.05, \n",
    "                             random_state=None)\n",
    "\n",
    "scale_data(data, [(1, 4), (3, 8)], inplace=True)\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a661d9-142b-4bf8-a4dd-b2d9ec9fae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moon graph\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(data[labels==0, 0], data[labels==0, 1], \n",
    "               c='orange', s=40, label='oranges')\n",
    "ax.scatter(data[labels==1, 0], data[labels==1, 1], \n",
    "               c='blue', s=40, label='blues')\n",
    "\n",
    "ax.set(xlabel='X',\n",
    "       ylabel='Y',\n",
    "       title='moons')\n",
    " \n",
    "\n",
    "ax.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e1ea6-4410-4dd1-983a-99ec6e003ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as ds\n",
    "data, labels = ds.make_circles(n_samples=100, \n",
    "                             shuffle=True, \n",
    "                             noise=0.05, \n",
    "                             random_state=None)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(data[labels==0, 0], data[labels==0, 1], \n",
    "               c='orange', s=40, label='oranges')\n",
    "ax.scatter(data[labels==1, 0], data[labels==1, 1], \n",
    "               c='blue', s=40, label='blues')\n",
    "\n",
    "ax.set(xlabel='X',\n",
    "       ylabel='Y',\n",
    "       title='circles')\n",
    "\n",
    "\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f058343b-fe89-4016-973e-37b2512da0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplots_adjust(bottom=.05, top=.9, left=.05, right=.95)\n",
    "\n",
    "plt.subplot(321)\n",
    "plt.title(\"One informative feature, one cluster per class\", fontsize='small')\n",
    "X1, Y1 = make_classification(n_features=2, n_redundant=0, n_informative=1,\n",
    "                             n_clusters_per_class=1)\n",
    "plt.scatter(X1[:, 0], X1[:, 1], marker='o', c=Y1,\n",
    "            s=25, edgecolor='k')\n",
    "\n",
    "plt.subplot(322)\n",
    "plt.title(\"Two informative features, one cluster per class\", fontsize='small')\n",
    "X1, Y1 = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                             n_clusters_per_class=1)\n",
    "plt.scatter(X1[:, 0], X1[:, 1], marker='o', c=Y1,\n",
    "            s=25, edgecolor='k')\n",
    "\n",
    "plt.subplot(323)\n",
    "plt.title(\"Two informative features, two clusters per class\",\n",
    "          fontsize='small')\n",
    "X2, Y2 = make_classification(n_features=2, \n",
    "                             n_redundant=0, \n",
    "                             n_informative=2)\n",
    "plt.scatter(X2[:, 0], X2[:, 1], marker='o', c=Y2,\n",
    "            s=25, edgecolor='k')\n",
    "\n",
    "plt.subplot(324)\n",
    "plt.title(\"Multi-class, two informative features, one cluster\",\n",
    "          fontsize='small')\n",
    "X1, Y1 = make_classification(n_features=2, \n",
    "                             n_redundant=0, \n",
    "                             n_informative=2,\n",
    "                             n_clusters_per_class=1, \n",
    "                             n_classes=3)\n",
    "plt.scatter(X1[:, 0], X1[:, 1], marker='o', c=Y1,\n",
    "            s=25, edgecolor='k')\n",
    "\n",
    "\n",
    "plt.subplot(325)\n",
    "plt.title(\"Gaussian divided into three quantiles\", fontsize='small')\n",
    "X1, Y1 = make_gaussian_quantiles(n_features=2, n_classes=3)\n",
    "plt.scatter(X1[:, 0], X1[:, 1], marker='o', c=Y1,\n",
    "            s=25, edgecolor='k')\n",
    "\n",
    "plt.show()  # various graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d793ca75-1bbf-4691-be43-bc24082b72cd",
   "metadata": {},
   "source": [
    "## Exercices\n",
    "\n",
    "### Exercice 1\n",
    "Créez deux clusters qui ressemblent à celui-ci :\n",
    "\n",
    "<center><img src=\"img/cluster1.png\" width=\"60%\"></center>\n",
    "\n",
    "Deux ensembles de tests qui sont séparables avec un perceptron.\n",
    "\n",
    "### Exercice 2\n",
    "Créez deux clusters similaires à l'image suivante :\n",
    "<center><img src=\"img/cluster2.png\" width=\"60%\"></center>\n",
    "\n",
    "### Exercice 3\n",
    "Créez un ensemble de données avec cinq classes \"Tigre\", \"Lion\", \"Pingouin\", \"Dauphin\" et \"Python\". Les ensembles devraient ressembler au diagramme suivant :\n",
    "\n",
    "<center><img src=\"img/cluster3.png\" width=\"60%\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2518d844-bae2-43e2-a03b-841d16b91db4",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "### Solution à l'exercice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469dc6e1-ca71-44e4-ba13-3c4f32b26519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution to exercise1 graph\n",
    "data, labels = make_blobs(n_samples=100, \n",
    "                            cluster_std = 0.5,\n",
    "                            centers=[[1, 4] ,[4, 1]],\n",
    "                            random_state=1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colours = [\"orange\", \"green\"]\n",
    "label_name = [\"Tigers\", \"Lions\"]\n",
    "for label in range(0, 2):\n",
    "    ax.scatter(data[labels==label, 0], data[labels==label, 1], \n",
    "               c=colours[label], s=40, label=label_name[label])\n",
    "\n",
    "\n",
    "ax.set(xlabel='X',\n",
    "       ylabel='Y',\n",
    "       title='dataset')\n",
    "\n",
    "\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d13f40-ec33-45a4-abca-8c5bab376b88",
   "metadata": {},
   "source": [
    "### Solution à l'exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a5f7b8-3050-42b1-b7f5-a745227a13a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution to exercise2 graph\n",
    "data, labels = make_blobs(n_samples=100, \n",
    "                            cluster_std = 0.5,\n",
    "                            centers=[[2, 2] ,[4, 4]],\n",
    "                            random_state=1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colours = [\"orange\", \"green\"]\n",
    "label_name = [\"ham\", \"spam\"]\n",
    "for label in range(0, 2):\n",
    "    ax.scatter(data[labels==label, 0], data[labels==label, 1], \n",
    "               c=colours[label], s=40, label=label_name[label])\n",
    "\n",
    "\n",
    "ax.set(xlabel='X',\n",
    "       ylabel='Y',\n",
    "       title='dataset')\n",
    "\n",
    "\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbaba1b-878f-40f0-a3b3-659c22530c92",
   "metadata": {},
   "source": [
    "### Solution à l'exercice 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd72a28d-2579-4aa3-9b8b-6f66c97b4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as ds\n",
    "data, labels = ds.make_circles(n_samples=100, \n",
    "                               shuffle=True, \n",
    "                               noise=0.05, \n",
    "                               random_state=42)\n",
    "\n",
    "centers = [[3, 4], [5, 3], [4.5, 6]]\n",
    "data2, labels2 = make_blobs(n_samples=100, \n",
    "                            cluster_std = 0.5,\n",
    "                            centers=centers,\n",
    "                            random_state=1)\n",
    "\n",
    "\n",
    "#for i in range(len(centers)-1, -1, -1):\n",
    "#    labels2[labels2==0+i] = i+2\n",
    "labels2 += +2\n",
    "    \n",
    "print(labels2)\n",
    "labels = np.concatenate([labels, labels2])\n",
    "data = data * [1.2, 1.8] + [3, 4]\n",
    "\n",
    "data = np.concatenate([data, data2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b622b031-0f77-448d-9b50-f5044fbfb8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution graph\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colours = [\"orange\", \"blue\", \"magenta\", \"yellow\", \"green\"]\n",
    "label_name = [\"Tiger\", \"Lion\", \"Penguin\", \"Dolphin\", \"Python\"]\n",
    "for label in range(0, len(centers)+2):\n",
    "    ax.scatter(data[labels==label, 0], data[labels==label, 1], \n",
    "               c=colours[label], s=40, label=label_name[label])\n",
    "\n",
    "\n",
    "ax.set(xlabel='X',\n",
    "       ylabel='Y',\n",
    "       title='dataset')\n",
    "\n",
    "\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc00b48",
   "metadata": {},
   "source": [
    "[Suivant](7_train_test.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
