{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47cc04f3-20b6-4914-acfd-0dd7c7f1c8b8",
   "metadata": {},
   "source": [
    "# 7. Ensembles d'apprentissage et de test en divisant les données d'apprentissage et de test\n",
    "\n",
    "## 1 Données d'apprentissage, de test et d'évaluation\n",
    "\n",
    "Vous avez vos données prêtes et vous êtes impatient de commencer l'entraînement du classificateur ? Mais attention : Lorsque votre classifieur sera terminé, vous aurez besoin de données de test pour l'évaluer. Si vous évaluez votre classificateur avec les données utilisées pour l'apprentissage, vous pouvez obtenir des résultats étonnamment bons. Ce que nous voulons réellement tester, c'est la performance de la classification sur des données inconnues.\n",
    "\n",
    "Pour ce faire, nous devons diviser nos données en deux parties :\n",
    "\n",
    "1. Un ensemble d'apprentissage avec lequel l'algorithme d'apprentissage adapte ou apprend le modèle.\n",
    "2. Un ensemble de test pour évaluer la performance de généralisation du modèle.\n",
    "\n",
    "Si l'on considère le fonctionnement normal de l'apprentissage automatique, l'idée d'une séparation entre les données d'apprentissage et les données de test est logique. Les systèmes existants s'entraînent sur des données existantes et si de nouvelles données (provenant de clients, de capteurs ou d'autres sources) arrivent, le classificateur entraîné doit prédire ou classer ces nouvelles données. Nous pouvons simuler cela pendant la formation avec un ensemble de données d'apprentissage et de test - les données de test sont une simulation des \"futures données\" qui entreront dans le système pendant la production.\n",
    "\n",
    "<center><img src=\"img/illustration7_1.png\" width=\"50%\"></center>\n",
    "\n",
    "Dans ce chapitre sur l'apprentissage automatique, nous allons apprendre à effectuer le fractionnement avec Python.\n",
    "\n",
    "Nous verrons également qu'il n'est pas nécessaire de le faire manuellement, car la fonction train_test_split du module model_selection peut le faire pour nous.\n",
    "\n",
    "Si l'ensemble de données est trié par étiquette, nous devrons le mélanger avant de le diviser.\n",
    "\n",
    "<center><img src=\"img/illustration7_2.png\" width=\"60%\"></center>\n",
    "\n",
    "Nous avons séparé l'ensemble de données en un ensemble de données d'apprentissage (ou de formation) et un ensemble de données de test. La meilleure pratique consiste à le diviser en un jeu de données d'apprentissage, de test et d'évaluation.\n",
    "\n",
    "Nous allons entraîner notre modèle (classificateur) étape par étape et chaque fois le résultat doit être testé. Si nous n'avons qu'un jeu de données de test. Les résultats des tests pourraient se retrouver dans le modèle. Nous utiliserons donc un jeu de données d'évaluation pour la phase d'apprentissage complète. Lorsque notre classificateur est terminé, nous le vérifions avec l'ensemble de données de test, qu'il n'a pas \"vu\" auparavant !\n",
    "<center><img src=\"img/illustration7_3.png\" width=\"40%\"></center>\n",
    "\n",
    "Dans la suite de cette présentation, nous n'utiliserons que les divisions en ensembles de données d'apprentissage et de test.\n",
    "\n",
    "## Exemple de fractionnement : Jeu de données Iris\n",
    "\n",
    "Nous allons démontrer les sujets abordés précédemment à l'aide du jeu de données Iris.\n",
    "\n",
    "Les 150 ensembles de données de l'ensemble de données Iris sont triés, c'est-à-dire que les 50 premières données correspondent à la première classe de fleurs (0 = Setosa), les 50 suivantes à la deuxième classe de fleurs (1 = Versicolor) et les données restantes correspondent à la dernière classe (2 = Virginica).\n",
    "\n",
    "Si nous devions diviser nos données dans le rapport 2/3 (ensemble d'apprentissage) et 1/3 (ensemble de test), l'ensemble d'apprentissage contiendrait toutes les fleurs des deux premières classes et l'ensemble de test toutes les fleurs de la troisième classe de fleurs. Le classificateur ne pourrait apprendre que deux classes et la troisième classe serait complètement inconnue. Il est donc urgent de mélanger les données.\n",
    "\n",
    "En supposant que tous les échantillons sont indépendants les uns des autres, nous voulons mélanger l'ensemble de données de façon aléatoire avant de le diviser comme indiqué ci-dessus.\n",
    "\n",
    "Dans ce qui suit, nous divisons les données manuellement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177759e4-22bd-4cbc-80de-53dd7c034f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc5daef-9dc5-4201-a6e3-8b604b9622b0",
   "metadata": {},
   "source": [
    "L'examen des étiquettes de iris.target nous montre que les données sont triées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d769c8d-4274-44e4-b1cf-c99e49bc9c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2382f1ae-365d-49d3-b8bf-62294752079e",
   "metadata": {},
   "source": [
    "La première chose à faire est de réorganiser les données de manière à ce qu'elles ne soient plus triées. Pour cela, nous allons utiliser la fonction de permutation du sous-module aléatoire de Numpy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86954a8a-0093-493d-8ec9-db6e4ed3a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_samples = 12\n",
    "learnset_data = iris.data[indices[:-n_test_samples]]\n",
    "learnset_labels = iris.target[indices[:-n_test_samples]]\n",
    "testset_data = iris.data[indices[-n_test_samples:]]\n",
    "testset_labels = iris.target[indices[-n_test_samples:]]\n",
    "print(learnset_data[:4], learnset_labels[:4])\n",
    "print(testset_data[:4], testset_labels[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394928f6-4ff9-4bd6-8b04-7dbdb98889c3",
   "metadata": {},
   "source": [
    "## Fractionnement avec Sklearn\n",
    "\n",
    "Même s'il n'était pas difficile de diviser manuellement les données en un ensemble d'apprentissage (train) et un ensemble d'évaluation (test), nous n'avons pas besoin d'effectuer la division manuellement comme indiqué ci-dessus. Comme cela est souvent nécessaire dans l'apprentissage automatique, scikit-learn dispose d'une fonction prédéfinie pour diviser les données en ensembles de formation et de test.\n",
    "\n",
    "Nous allons en faire la démonstration ci-dessous. Nous utiliserons 80 % des données pour la formation et 20 % pour le test. Nous aurions tout aussi bien pu prendre 70 % et 30 %, car il n'y a pas de règle absolue. Le plus important est que vous évaluez votre système de manière équitable sur la base de données qu'il n'a pas vues pendant l'exercice ! En outre, il doit y avoir suffisamment de données dans les deux ensembles de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f28d0fd-18b4-409a-bb84-680e0eef27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()\n",
    "data, labels = iris.data, iris.target\n",
    "\n",
    "res = train_test_split(data, labels, \n",
    "                       train_size=0.8,\n",
    "                       test_size=0.2,\n",
    "                       random_state=42)\n",
    "train_data, test_data, train_labels, test_labels = res    \n",
    "\n",
    "n = 7\n",
    "print(f\"The first {n} data sets:\")\n",
    "print(test_data[:7])\n",
    "print(f\"The corresponding {n} labels:\")\n",
    "print(test_labels[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8601592-2ac9-4983-b2f8-cfbf75892a20",
   "metadata": {},
   "source": [
    "## Echantillon aléatoire stratifié\n",
    "\n",
    "En particulier avec des quantités de données relativement faibles, il est préférable de stratifier la division. La stratification signifie que nous conservons la proportion de classe originale de l'ensemble de données dans les ensembles de test et de formation. Nous calculons les proportions de classe de la division précédente en pourcentage en utilisant le code suivant. Pour calculer le nombre d'occurrences de chaque classe, nous utilisons la fonction numpy ```bincount```. Elle compte le nombre d'occurrences de chaque valeur dans le tableau d'entiers non-négatifs passé en argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc333115-36f8-4f62-bb0f-5dc9e3d819e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print('All:', np.bincount(labels) / float(len(labels)) * 100.0)\n",
    "print('Training:', np.bincount(train_labels) / float(len(train_labels)) * 100.0)\n",
    "print('Test:', np.bincount(test_labels) / float(len(test_labels)) * 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7ad3f-c0c3-4743-825f-25691a59a0a9",
   "metadata": {},
   "source": [
    "Pour stratifier la division, nous pouvons passer le tableau d'étiquettes comme argument supplémentaire à la fonction train_test_split :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e879fca-3e9d-4ed9-a62d-544137a2b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()\n",
    "data, labels = iris.data, iris.target\n",
    "\n",
    "res = train_test_split(data, labels, \n",
    "                       train_size=0.8,\n",
    "                       test_size=0.2,\n",
    "                       random_state=42,\n",
    "                       stratify=labels)\n",
    "train_data, test_data, train_labels, test_labels = res \n",
    "\n",
    "print('All:', np.bincount(labels) / float(len(labels)) * 100.0)\n",
    "print('Training:', np.bincount(train_labels) / float(len(train_labels)) * 100.0)\n",
    "print('Test:', np.bincount(test_labels) / float(len(test_labels)) * 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9031a611-617c-4456-a4be-17d8ce3bd34f",
   "metadata": {},
   "source": [
    "C'était un exemple stupide pour tester l'échantillon aléatoire stratifié, car l'ensemble des données Iris a les mêmes proportions, c'est-à-dire que chaque classe a 50 éléments.\n",
    "\n",
    "Nous allons maintenant travailler avec le fichier ```strange_flowers.txt``` du répertoire ```data```. Ce jeu de données est créé dans le chapitre Générer des jeux de données en Python. Les classes de ce jeu de données ont des nombres d'éléments différents. Tout d'abord, nous chargeons les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65caa1a9-fda2-4af3-aa3a-0bea4ea3bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = np.loadtxt(\"data/strange_flowers.txt\", delimiter=\" \")\n",
    "data = content[:, :-1]    # cut of the target column\n",
    "labels = content[:, -1]\n",
    "labels.dtype\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a40c5-df6c-47c1-9fdf-18580757aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = train_test_split(data, labels, \n",
    "                       train_size=0.8,\n",
    "                       test_size=0.2,\n",
    "                       random_state=42,\n",
    "                       stratify=labels)\n",
    "train_data, test_data, train_labels, test_labels = res \n",
    "\n",
    "# np.bincount expects non negative integers:\n",
    "print('All:', np.bincount(labels.astype(int))  / float(len(labels)) * 100.0)\n",
    "print('Training:', np.bincount(train_labels.astype(int)) / float(len(train_labels)) * 100.0)\n",
    "print('Test:', np.bincount(test_labels.astype(int)) / float(len(test_labels)) * 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b01d2",
   "metadata": {},
   "source": [
    "[Suivant](8_knn_python.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
